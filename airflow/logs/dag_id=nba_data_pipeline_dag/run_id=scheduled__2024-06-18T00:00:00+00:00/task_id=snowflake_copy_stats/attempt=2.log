[2024-06-19T00:39:26.277+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:39:26.319+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:39:26.329+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:39:26.329+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-19T00:39:26.342+0000] {taskinstance.py:2330} INFO - Executing <Task(SQLExecuteQueryOperator): snowflake_copy_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:39:26.352+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'snowflake_copy_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '601', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp25ob86iu']
[2024-06-19T00:39:26.354+0000] {standard_task_runner.py:91} INFO - Job 601: Subtask snowflake_copy_stats
[2024-06-19T00:39:26.354+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=4922) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:39:26.355+0000] {standard_task_runner.py:63} INFO - Started process 4930 to run task
[2024-06-19T00:39:26.448+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:39:26.607+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='snowflake_copy_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:39:26.608+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:39:26.623+0000] {sql.py:276} INFO - Executing: 
        USE NBA_STATS_ANALYTICS;
        USE WAREHOUSE NBA_STATS_WAREHOUSE;
        COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');
        
[2024-06-19T00:39:26.649+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T00:39:26.893+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T00:39:26.894+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.3, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.39
[2024-06-19T00:39:26.894+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-19T00:39:26.895+0000] {connection.py:1249} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T00:39:26.967+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T00:39:27.243+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:39:27.244+0000] {sql.py:487} INFO - Running statement: USE NBA_STATS_ANALYTICS;, parameters: None
[2024-06-19T00:39:27.332+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:39:27.332+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T00:39:27.333+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T00:39:27.333+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a47-0001-e499-0006-023e0001c5ca
[2024-06-19T00:39:27.333+0000] {sql.py:487} INFO - Running statement: USE WAREHOUSE NBA_STATS_WAREHOUSE;, parameters: None
[2024-06-19T00:39:27.406+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:39:27.406+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T00:39:27.407+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T00:39:27.407+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a47-0001-e49d-0006-023e0001f4b2
[2024-06-19T00:39:27.407+0000] {sql.py:487} INFO - Running statement: COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');, parameters: None
[2024-06-19T00:39:27.481+0000] {connection.py:762} INFO - closed
[2024-06-19T00:39:27.505+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-06-19T00:39:27.538+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:39:27.539+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 397, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (02000): 01b51a47-0001-e49c-0006-023e000175de: SQL compilation error:
Stage 'NBA_STATS_ANALYTICS.PUBLIC.SNOW_S3_STAGE' does not exist or not authorized.
[2024-06-19T00:39:27.563+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=snowflake_copy_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T003926, end_date=20240619T003927
[2024-06-19T00:39:27.576+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 601 for task snowflake_copy_stats (002003 (02000): 01b51a47-0001-e49c-0006-023e000175de: SQL compilation error:
Stage 'NBA_STATS_ANALYTICS.PUBLIC.SNOW_S3_STAGE' does not exist or not authorized.; 4930)
[2024-06-19T00:39:27.617+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-19T00:39:27.649+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:39:27.652+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T00:49:36.331+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:49:36.374+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:49:36.383+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:49:36.383+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-19T00:49:36.395+0000] {taskinstance.py:2330} INFO - Executing <Task(SQLExecuteQueryOperator): snowflake_copy_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:49:36.405+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'snowflake_copy_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '620', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphpr5byzw']
[2024-06-19T00:49:36.408+0000] {standard_task_runner.py:91} INFO - Job 620: Subtask snowflake_copy_stats
[2024-06-19T00:49:36.408+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=10028) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:49:36.409+0000] {standard_task_runner.py:63} INFO - Started process 10036 to run task
[2024-06-19T00:49:36.502+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:49:36.670+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='snowflake_copy_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:49:36.671+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:49:36.685+0000] {sql.py:276} INFO - Executing: 
        USE WAREHOUSE NBA_STATS_WAREHOUSE;
        USE NBA_STATS_ANALYTICS;
        COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');
        
[2024-06-19T00:49:36.711+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T00:49:36.955+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T00:49:36.956+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.3, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.39
[2024-06-19T00:49:36.956+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-19T00:49:36.956+0000] {connection.py:1249} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T00:49:37.027+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T00:49:37.343+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:49:37.344+0000] {sql.py:487} INFO - Running statement: USE WAREHOUSE NBA_STATS_WAREHOUSE;, parameters: None
[2024-06-19T00:49:37.414+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:49:37.414+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T00:49:37.415+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T00:49:37.415+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a51-0001-e497-0006-023e0001d57e
[2024-06-19T00:49:37.415+0000] {sql.py:487} INFO - Running statement: USE NBA_STATS_ANALYTICS;, parameters: None
[2024-06-19T00:49:37.483+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T00:49:37.483+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T00:49:37.483+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T00:49:37.484+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a51-0001-e498-0006-023e0001b606
[2024-06-19T00:49:37.484+0000] {sql.py:487} INFO - Running statement: COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');, parameters: None
[2024-06-19T00:49:38.187+0000] {connection.py:762} INFO - closed
[2024-06-19T00:49:38.214+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-06-19T00:49:38.266+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:49:38.267+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 397, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100080 (22000): 01b51a51-0001-e497-0006-023e0001d582: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.
[2024-06-19T00:49:38.291+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=snowflake_copy_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T004936, end_date=20240619T004938
[2024-06-19T00:49:38.303+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 620 for task snowflake_copy_stats (100080 (22000): 01b51a51-0001-e497-0006-023e0001d582: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.; 10036)
[2024-06-19T00:49:38.313+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-19T00:49:38.345+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:49:38.347+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:12:13.807+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:12:13.850+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:12:13.859+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:12:13.859+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-19T01:12:13.872+0000] {taskinstance.py:2330} INFO - Executing <Task(SQLExecuteQueryOperator): snowflake_copy_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:12:13.888+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'snowflake_copy_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '639', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp0jkv3hwn']
[2024-06-19T01:12:13.893+0000] {standard_task_runner.py:91} INFO - Job 639: Subtask snowflake_copy_stats
[2024-06-19T01:12:13.895+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=16450) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:12:13.895+0000] {standard_task_runner.py:63} INFO - Started process 16462 to run task
[2024-06-19T01:12:14.042+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:12:14.249+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='snowflake_copy_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:12:14.251+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:12:14.265+0000] {sql.py:276} INFO - Executing: 
        USE WAREHOUSE NBA_STATS_WAREHOUSE;
        USE NBA_STATS_ANALYTICS;
        COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');
        
[2024-06-19T01:12:14.293+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T01:12:14.545+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T01:12:14.546+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.3, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.39
[2024-06-19T01:12:14.547+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-19T01:12:14.547+0000] {connection.py:1249} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T01:12:14.625+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T01:12:14.943+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:12:14.944+0000] {sql.py:487} INFO - Running statement: USE WAREHOUSE NBA_STATS_WAREHOUSE;, parameters: None
[2024-06-19T01:12:14.998+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:12:14.999+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T01:12:14.999+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T01:12:14.999+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a68-0001-e498-0006-023e0001b63a
[2024-06-19T01:12:14.999+0000] {sql.py:487} INFO - Running statement: USE NBA_STATS_ANALYTICS;, parameters: None
[2024-06-19T01:12:15.070+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:12:15.070+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T01:12:15.070+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T01:12:15.071+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a68-0001-e495-0006-023e000185d2
[2024-06-19T01:12:15.071+0000] {sql.py:487} INFO - Running statement: COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');, parameters: None
[2024-06-19T01:12:16.189+0000] {connection.py:762} INFO - closed
[2024-06-19T01:12:16.257+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-06-19T01:12:16.329+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:12:16.330+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 397, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100080 (22000): 01b51a68-0001-e499-0006-023e0001c656: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.
[2024-06-19T01:12:16.354+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=snowflake_copy_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T011213, end_date=20240619T011216
[2024-06-19T01:12:16.366+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 639 for task snowflake_copy_stats (100080 (22000): 01b51a68-0001-e499-0006-023e0001c656: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.; 16462)
[2024-06-19T01:12:16.405+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-19T01:12:16.437+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:12:16.439+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:43:09.751+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:43:09.795+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:43:09.804+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:43:09.805+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-19T01:43:09.818+0000] {taskinstance.py:2330} INFO - Executing <Task(SQLExecuteQueryOperator): snowflake_copy_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:43:09.828+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'snowflake_copy_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '662', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpj8qd79iq']
[2024-06-19T01:43:09.831+0000] {standard_task_runner.py:91} INFO - Job 662: Subtask snowflake_copy_stats
[2024-06-19T01:43:09.831+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=23668) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:43:09.831+0000] {standard_task_runner.py:63} INFO - Started process 23676 to run task
[2024-06-19T01:43:09.931+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:43:10.108+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='snowflake_copy_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:43:10.109+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:43:10.124+0000] {sql.py:276} INFO - Executing: 
        USE WAREHOUSE NBA_STATS_WAREHOUSE;
        USE NBA_STATS_ANALYTICS;
        COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');
        
[2024-06-19T01:43:10.151+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T01:43:10.397+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-19T01:43:10.398+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.3, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.39
[2024-06-19T01:43:10.398+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-19T01:43:10.398+0000] {connection.py:1249} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T01:43:10.464+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-19T01:43:10.834+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:43:10.834+0000] {sql.py:487} INFO - Running statement: USE WAREHOUSE NBA_STATS_WAREHOUSE;, parameters: None
[2024-06-19T01:43:10.911+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:43:10.912+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T01:43:10.912+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T01:43:10.912+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a87-0001-e495-0006-023e00018626
[2024-06-19T01:43:10.913+0000] {sql.py:487} INFO - Running statement: USE NBA_STATS_ANALYTICS;, parameters: None
[2024-06-19T01:43:11.000+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-19T01:43:11.000+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-19T01:43:11.000+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-19T01:43:11.000+0000] {snowflake.py:410} INFO - Snowflake query id: 01b51a87-0001-e49a-0006-023e0001a6f6
[2024-06-19T01:43:11.001+0000] {sql.py:487} INFO - Running statement: COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');, parameters: None
[2024-06-19T01:43:14.196+0000] {connection.py:762} INFO - closed
[2024-06-19T01:43:14.225+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-06-19T01:43:14.264+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:43:14.265+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 397, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100080 (22000): 01b51a87-0001-e499-0006-023e0001c6a2: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.
[2024-06-19T01:43:14.289+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=snowflake_copy_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T014309, end_date=20240619T014314
[2024-06-19T01:43:14.302+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 662 for task snowflake_copy_stats (100080 (22000): 01b51a87-0001-e499-0006-023e0001c6a2: Number of columns in file (30) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[30]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.; 23676)
[2024-06-19T01:43:14.345+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-19T01:43:14.378+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:43:14.380+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:37:05.630+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:37:05.671+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:37:05.679+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:37:05.680+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-20T16:37:05.692+0000] {taskinstance.py:2330} INFO - Executing <Task(SQLExecuteQueryOperator): snowflake_copy_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:37:05.700+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7312) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:37:05.702+0000] {standard_task_runner.py:63} INFO - Started process 7322 to run task
[2024-06-20T16:37:05.701+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'snowflake_copy_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1168', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpt11n2tx7']
[2024-06-20T16:37:05.703+0000] {standard_task_runner.py:91} INFO - Job 1168: Subtask snowflake_copy_stats
[2024-06-20T16:37:05.797+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.snowflake_copy_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:37:05.939+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='snowflake_copy_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:37:05.940+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:37:05.953+0000] {sql.py:276} INFO - Executing: 
        USE WAREHOUSE NBA_STATS_WAREHOUSE;
        USE NBA_STATS_ANALYTICS;
        COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');
        
[2024-06-20T16:37:05.977+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-20T16:37:06.231+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-06-20T16:37:06.232+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.3, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.39
[2024-06-20T16:37:06.232+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-20T16:37:06.232+0000] {connection.py:1249} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-20T16:37:06.298+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-06-20T16:37:06.543+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-20T16:37:06.543+0000] {sql.py:487} INFO - Running statement: USE WAREHOUSE NBA_STATS_WAREHOUSE;, parameters: None
[2024-06-20T16:37:06.612+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-20T16:37:06.612+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-20T16:37:06.613+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-20T16:37:06.613+0000] {snowflake.py:410} INFO - Snowflake query id: 01b523a5-0001-e499-0006-023e0002372e
[2024-06-20T16:37:06.613+0000] {sql.py:487} INFO - Running statement: USE NBA_STATS_ANALYTICS;, parameters: None
[2024-06-20T16:37:06.680+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-06-20T16:37:06.681+0000] {sql.py:496} INFO - Rows affected: 1
[2024-06-20T16:37:06.681+0000] {snowflake.py:409} INFO - Rows affected: 1
[2024-06-20T16:37:06.681+0000] {snowflake.py:410} INFO - Snowflake query id: 01b523a5-0001-e499-0006-023e00023732
[2024-06-20T16:37:06.681+0000] {sql.py:487} INFO - Running statement: COPY INTO NBA_STATS.player_stats
        FROM @SNOW_S3_STAGE/player_stats.csv
        FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT');, parameters: None
[2024-06-20T16:37:07.423+0000] {connection.py:762} INFO - closed
[2024-06-20T16:37:07.490+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-06-20T16:37:08.227+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:37:08.228+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 397, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 492, in _run_command
    cur.execute(sql_statement)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 100080 (22000): 01b523a5-0001-e49c-0006-023e000227a2: Number of columns in file (29) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[29]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.
[2024-06-20T16:37:08.251+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=snowflake_copy_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T163705, end_date=20240620T163708
[2024-06-20T16:37:08.263+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 1168 for task snowflake_copy_stats (100080 (22000): 01b523a5-0001-e49c-0006-023e000227a2: Number of columns in file (29) does not match that of the corresponding table (28), use file format option error_on_column_count_mismatch=false to ignore this error
  File 'player_stats.csv', line 3, character 1
  Row 1 starts at line 2, column "PLAYER_STATS"[29]
  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.; 7322)
[2024-06-20T16:37:08.290+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-20T16:37:08.326+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:37:08.330+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
