[2024-06-19T00:01:34.700+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:01:34.783+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:01:34.794+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:01:34.796+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:01:34.816+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:01:34.832+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '566', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp3dgoutjy']
[2024-06-19T00:01:34.841+0000] {standard_task_runner.py:91} INFO - Job 566: Subtask fetch_player_stats
[2024-06-19T00:01:34.841+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=9130) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:01:34.844+0000] {standard_task_runner.py:63} INFO - Started process 9238 to run task
[2024-06-19T00:01:35.010+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:01:35.223+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:01:35.226+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:02:23.743+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T00:02:23.744+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:02:23.796+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T000134, end_date=20240619T000223
[2024-06-19T00:02:23.841+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:02:23.879+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:02:23.882+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T00:36:36.275+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:36:36.339+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:36:36.348+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:36:36.348+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:36:36.363+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:36:36.384+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '592', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp94eh8qir']
[2024-06-19T00:36:36.390+0000] {standard_task_runner.py:91} INFO - Job 592: Subtask fetch_player_stats
[2024-06-19T00:36:36.390+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3034) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:36:36.391+0000] {standard_task_runner.py:63} INFO - Started process 3133 to run task
[2024-06-19T00:36:36.551+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:36:36.820+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:36:36.824+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:37:20.675+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T00:37:20.675+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:37:20.728+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T003636, end_date=20240619T003720
[2024-06-19T00:37:20.771+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:37:20.811+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:37:20.813+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T00:46:44.262+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:46:44.348+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:46:44.360+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:46:44.360+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:46:44.374+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:46:44.389+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '611', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpgwnv118p']
[2024-06-19T00:46:44.397+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7778) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:46:44.396+0000] {standard_task_runner.py:91} INFO - Job 611: Subtask fetch_player_stats
[2024-06-19T00:46:44.398+0000] {standard_task_runner.py:63} INFO - Started process 7887 to run task
[2024-06-19T00:46:44.546+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:46:44.714+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:46:44.717+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:47:29.191+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T00:47:29.192+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:47:29.244+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T004644, end_date=20240619T004729
[2024-06-19T00:47:29.265+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:47:29.304+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:47:29.306+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:09:20.469+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:09:20.531+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:09:20.557+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:09:20.558+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:09:20.579+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:09:20.598+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '630', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp0qhz_wog']
[2024-06-19T01:09:20.605+0000] {standard_task_runner.py:91} INFO - Job 630: Subtask fetch_player_stats
[2024-06-19T01:09:20.605+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=14304) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:09:20.610+0000] {standard_task_runner.py:63} INFO - Started process 14374 to run task
[2024-06-19T01:09:20.763+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:09:20.994+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:09:20.998+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:10:06.046+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T01:10:06.046+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:10:06.099+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T010920, end_date=20240619T011006
[2024-06-19T01:10:06.154+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:10:06.196+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:10:06.200+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:40:14.631+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:40:14.720+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:40:14.737+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:40:14.737+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:40:14.765+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:40:14.793+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '653', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpasdyb48b']
[2024-06-19T01:40:14.799+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21834) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:40:14.800+0000] {standard_task_runner.py:91} INFO - Job 653: Subtask fetch_player_stats
[2024-06-19T01:40:14.802+0000] {standard_task_runner.py:63} INFO - Started process 21909 to run task
[2024-06-19T01:40:14.978+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:40:15.170+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:40:15.173+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:41:01.975+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T01:41:01.976+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:41:02.040+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T014014, end_date=20240619T014102
[2024-06-19T01:41:02.095+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:41:02.137+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:41:02.139+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:55:36.650+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:55:36.725+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:55:36.733+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:55:36.733+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:55:36.752+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:55:36.772+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '672', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp112qwi94']
[2024-06-19T01:55:36.784+0000] {standard_task_runner.py:91} INFO - Job 672: Subtask fetch_player_stats
[2024-06-19T01:55:36.783+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=26766) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:55:36.786+0000] {standard_task_runner.py:63} INFO - Started process 26842 to run task
[2024-06-19T01:55:36.960+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:55:37.199+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:55:37.200+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:56:21.020+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T01:56:21.021+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:56:21.073+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T015536, end_date=20240619T015621
[2024-06-19T01:56:21.106+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:56:21.145+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:56:21.147+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T04:28:50.080+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T04:28:50.164+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T04:28:50.186+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T04:28:50.186+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T04:28:50.213+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T04:28:50.227+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '689', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpg5t7hpeh']
[2024-06-19T04:28:50.234+0000] {standard_task_runner.py:91} INFO - Job 689: Subtask fetch_player_stats
[2024-06-19T04:28:50.233+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3300) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T04:28:50.236+0000] {standard_task_runner.py:63} INFO - Started process 3412 to run task
[2024-06-19T04:28:50.362+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T04:28:50.610+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T04:28:50.612+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T04:29:34.066+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T04:29:34.067+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T04:29:34.119+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T042850, end_date=20240619T042934
[2024-06-19T04:29:34.154+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T04:29:34.193+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T04:29:34.195+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:53:57.529+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:53:57.598+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:53:57.612+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:53:57.614+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T13:53:57.637+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:53:57.653+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '706', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpkvyy88ph']
[2024-06-19T13:53:57.661+0000] {standard_task_runner.py:91} INFO - Job 706: Subtask fetch_player_stats
[2024-06-19T13:53:57.663+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=5130) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T13:53:57.666+0000] {standard_task_runner.py:63} INFO - Started process 5199 to run task
[2024-06-19T13:53:57.812+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T13:53:58.074+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:53:58.075+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:55:00.035+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T13:55:00.036+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:55:00.101+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T135357, end_date=20240619T135500
[2024-06-19T13:55:00.148+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:55:00.189+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:55:00.190+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T17:10:28.174+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T17:10:28.256+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:10:28.271+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:10:28.272+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T17:10:28.296+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T17:10:28.317+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3926) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T17:10:28.323+0000] {standard_task_runner.py:63} INFO - Started process 4015 to run task
[2024-06-19T17:10:28.322+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '726', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp0hf5opjv']
[2024-06-19T17:10:28.332+0000] {standard_task_runner.py:91} INFO - Job 726: Subtask fetch_player_stats
[2024-06-19T17:10:28.548+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T17:10:28.933+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T17:10:28.934+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T17:11:15.715+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T17:11:15.716+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T17:11:15.768+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T171028, end_date=20240619T171115
[2024-06-19T17:11:15.809+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T17:11:15.834+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T17:25:38.805+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T17:25:38.945+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:25:38.972+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:25:38.973+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T17:25:39.005+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T17:25:39.038+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '749', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpzzdg7olq']
[2024-06-19T17:25:39.049+0000] {standard_task_runner.py:91} INFO - Job 749: Subtask fetch_player_stats
[2024-06-19T17:25:39.048+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8459) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T17:25:39.055+0000] {standard_task_runner.py:63} INFO - Started process 8566 to run task
[2024-06-19T17:25:39.306+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T17:25:39.549+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T17:25:39.553+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T17:26:28.111+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T17:26:28.111+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T17:26:28.164+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T172538, end_date=20240619T172628
[2024-06-19T17:26:28.188+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T17:26:28.227+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T17:26:28.229+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T21:12:28.972+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T21:12:29.060+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T21:12:29.078+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T21:12:29.079+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T21:12:29.094+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-19T21:12:29.126+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=4320) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T21:12:29.127+0000] {standard_task_runner.py:63} INFO - Started process 4418 to run task
[2024-06-19T21:12:29.115+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '768', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpprecvdl7']
[2024-06-19T21:12:29.128+0000] {standard_task_runner.py:91} INFO - Job 768: Subtask fetch_player_stats
[2024-06-19T21:12:29.339+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T21:12:29.734+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T21:12:29.740+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T21:13:17.237+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-19T21:13:17.237+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T21:13:17.294+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T211229, end_date=20240619T211317
[2024-06-19T21:13:17.331+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T21:13:17.372+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T21:13:17.375+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:34:05.353+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:34:05.517+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:34:05.547+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:34:05.549+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:34:05.593+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:34:05.625+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '797', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpjrn3sc71']
[2024-06-20T11:34:05.638+0000] {standard_task_runner.py:91} INFO - Job 797: Subtask fetch_player_stats
[2024-06-20T11:34:05.639+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3252) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:34:05.650+0000] {standard_task_runner.py:63} INFO - Started process 3382 to run task
[2024-06-20T11:34:06.209+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:34:07.038+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:34:07.052+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:35:08.094+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T11:35:08.095+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:35:08.156+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T113405, end_date=20240620T113508
[2024-06-20T11:35:08.208+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:35:08.258+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T11:35:08.261+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:40:16.475+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:40:16.708+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:40:16.757+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:40:16.757+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:40:16.839+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:40:16.874+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7634) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:40:16.899+0000] {standard_task_runner.py:63} INFO - Started process 7870 to run task
[2024-06-20T11:40:16.881+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '832', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphrw3nh8_']
[2024-06-20T11:40:16.906+0000] {standard_task_runner.py:91} INFO - Job 832: Subtask fetch_player_stats
[2024-06-20T11:40:17.437+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:40:18.100+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:40:18.101+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:41:00.524+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T11:41:00.525+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:41:00.584+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T114016, end_date=20240620T114100
[2024-06-20T11:41:00.623+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:41:00.665+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T11:41:00.667+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:52:17.866+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:52:18.064+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:52:18.135+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:52:18.139+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:52:18.223+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:52:18.281+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '866', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpr4nuytzr']
[2024-06-20T11:52:18.297+0000] {standard_task_runner.py:91} INFO - Job 866: Subtask fetch_player_stats
[2024-06-20T11:52:18.292+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=14547) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:52:18.302+0000] {standard_task_runner.py:63} INFO - Started process 14779 to run task
[2024-06-20T11:52:18.775+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:52:19.428+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:52:19.440+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:53:01.213+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T11:53:01.213+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:53:01.272+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T115218, end_date=20240620T115301
[2024-06-20T11:53:01.296+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:53:01.338+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T11:53:01.340+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:12:14.579+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:12:14.844+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:12:14.915+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:12:14.916+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:12:15.010+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:12:15.072+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=22527) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:12:15.082+0000] {standard_task_runner.py:63} INFO - Started process 22759 to run task
[2024-06-20T12:12:15.074+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '915', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp93ziacyb']
[2024-06-20T12:12:15.090+0000] {standard_task_runner.py:91} INFO - Job 915: Subtask fetch_player_stats
[2024-06-20T12:12:15.705+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:12:16.269+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:12:16.278+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:13:01.001+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T12:13:01.002+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:13:01.095+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T121214, end_date=20240620T121301
[2024-06-20T12:13:01.131+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:13:01.175+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:13:01.177+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:20:39.419+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:20:39.578+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:20:39.615+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:20:39.615+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:20:39.660+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:20:39.689+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28709) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:20:39.694+0000] {standard_task_runner.py:63} INFO - Started process 28954 to run task
[2024-06-20T12:20:39.691+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '952', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmprj9xcfyc']
[2024-06-20T12:20:39.697+0000] {standard_task_runner.py:91} INFO - Job 952: Subtask fetch_player_stats
[2024-06-20T12:20:40.127+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:20:40.928+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:20:40.930+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:21:23.966+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T12:21:23.966+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:21:24.024+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T122039, end_date=20240620T122124
[2024-06-20T12:21:24.069+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:21:24.114+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:21:24.116+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:37:40.571+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:37:40.820+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:37:40.878+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:37:40.879+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:37:40.934+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:37:41.000+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=34270) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:37:41.012+0000] {standard_task_runner.py:63} INFO - Started process 34484 to run task
[2024-06-20T12:37:41.003+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '979', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp6ig1np4a']
[2024-06-20T12:37:41.018+0000] {standard_task_runner.py:91} INFO - Job 979: Subtask fetch_player_stats
[2024-06-20T12:37:41.524+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:37:42.321+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:37:42.322+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:38:06.543+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-06-20T12:38:06.544+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:38:06.550+0000] {process_utils.py:132} INFO - Sending 15 to group 34484. PIDs of all processes in the group: [34484]
[2024-06-20T12:38:06.551+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 34484
[2024-06-20T12:38:06.551+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-06-20T12:38:06.551+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:38:06.576+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 84, in fetch_player_stats
    time.sleep(1)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-06-20T12:38:06.581+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T123740, end_date=20240620T123806
[2024-06-20T12:38:06.594+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 979 for task fetch_player_stats ((psycopg2.errors.ForeignKeyViolation) insert or update on table "task_fail" violates foreign key constraint "task_fail_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(nba_data_pipeline_dag, fetch_player_stats, scheduled__2024-06-18T00:00:00+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(run_id)s, %(map_index)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'fetch_player_stats', 'dag_id': 'nba_data_pipeline_dag', 'run_id': 'scheduled__2024-06-18T00:00:00+00:00', 'map_index': -1, 'start_date': datetime.datetime(2024, 6, 20, 12, 37, 40, 821217, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2024, 6, 20, 12, 38, 6, 580936, tzinfo=Timezone('UTC')), 'duration': 25}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 34484)
[2024-06-20T12:38:06.644+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=34484, status='terminated', exitcode=1, started='12:37:40') (34484) terminated with exit code 1
[2024-06-20T12:39:33.806+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:39:34.047+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:39:34.098+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:39:34.102+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:39:34.206+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:39:34.285+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=36870) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:39:34.307+0000] {standard_task_runner.py:63} INFO - Started process 37105 to run task
[2024-06-20T12:39:34.284+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1001', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpqubuw_pj']
[2024-06-20T12:39:34.310+0000] {standard_task_runner.py:91} INFO - Job 1001: Subtask fetch_player_stats
[2024-06-20T12:39:34.839+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:39:35.544+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:39:35.552+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:40:23.297+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T12:40:23.297+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:40:23.356+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T123934, end_date=20240620T124023
[2024-06-20T12:40:23.385+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:40:23.458+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:40:23.465+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:49:08.024+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:49:08.230+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:49:08.282+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:49:08.284+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:49:08.335+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:49:08.416+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=42693) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:49:08.407+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1037', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpp0amqin1']
[2024-06-20T12:49:08.425+0000] {standard_task_runner.py:91} INFO - Job 1037: Subtask fetch_player_stats
[2024-06-20T12:49:08.427+0000] {standard_task_runner.py:63} INFO - Started process 42936 to run task
[2024-06-20T12:49:08.900+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:49:09.818+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:49:09.820+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:49:55.364+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T12:49:55.365+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:49:55.425+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T124908, end_date=20240620T124955
[2024-06-20T12:49:55.460+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:49:55.506+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:49:55.509+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:54:36.200+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:54:36.323+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:54:36.367+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:54:36.369+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:54:36.406+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:54:36.448+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=48843) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:54:36.456+0000] {standard_task_runner.py:63} INFO - Started process 48943 to run task
[2024-06-20T12:54:36.452+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1072', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpvshh3bfe']
[2024-06-20T12:54:36.465+0000] {standard_task_runner.py:91} INFO - Job 1072: Subtask fetch_player_stats
[2024-06-20T12:54:36.790+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:54:37.258+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:54:37.260+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:55:22.051+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T12:55:22.054+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:55:22.122+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T125436, end_date=20240620T125522
[2024-06-20T12:55:22.168+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:55:22.211+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:55:22.214+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T13:06:19.041+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T13:06:19.276+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T13:06:19.349+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T13:06:19.350+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T13:06:19.438+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T13:06:19.513+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=55107) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T13:06:19.519+0000] {standard_task_runner.py:63} INFO - Started process 55350 to run task
[2024-06-20T13:06:19.517+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1109', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpfqxlyb4f']
[2024-06-20T13:06:19.529+0000] {standard_task_runner.py:91} INFO - Job 1109: Subtask fetch_player_stats
[2024-06-20T13:06:20.121+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T13:06:20.829+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T13:06:20.836+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T13:07:05.000+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T13:07:05.000+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T13:07:05.055+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T130619, end_date=20240620T130705
[2024-06-20T13:07:05.115+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T13:07:05.156+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T13:07:05.159+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:34:08.839+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:34:08.985+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:34:09.001+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:34:09.004+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:34:09.052+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:34:09.075+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1143', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp4pnuo_l2']
[2024-06-20T16:34:09.087+0000] {standard_task_runner.py:91} INFO - Job 1143: Subtask fetch_player_stats
[2024-06-20T16:34:09.090+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=4417) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:34:09.091+0000] {standard_task_runner.py:63} INFO - Started process 4648 to run task
[2024-06-20T16:34:09.352+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:34:10.137+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:34:10.138+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:34:54.870+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T16:34:54.870+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:34:54.922+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T163408, end_date=20240620T163454
[2024-06-20T16:34:54.977+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T16:34:55.015+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:34:55.016+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:43:38.479+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:43:38.678+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:43:38.718+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:43:38.718+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:43:38.758+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:43:38.795+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=10084) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:43:38.792+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1178', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp3toof70w']
[2024-06-20T16:43:38.802+0000] {standard_task_runner.py:91} INFO - Job 1178: Subtask fetch_player_stats
[2024-06-20T16:43:38.796+0000] {standard_task_runner.py:63} INFO - Started process 10319 to run task
[2024-06-20T16:43:39.197+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:43:39.791+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:43:39.792+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:44:24.143+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:44:24.144+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 89, in fetch_player_stats
    top_player_stats = top_500_players[columns]
                       ^^^^^^^^^^^^^^^
NameError: name 'top_500_players' is not defined
[2024-06-20T16:44:24.175+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T164338, end_date=20240620T164424
[2024-06-20T16:44:24.186+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 1178 for task fetch_player_stats (name 'top_500_players' is not defined; 10319)
[2024-06-20T16:44:24.214+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-20T16:44:24.249+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:44:24.251+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:54:11.417+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:54:11.606+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:54:11.639+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:54:11.642+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:54:11.687+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:54:11.728+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=15687) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:54:11.738+0000] {standard_task_runner.py:63} INFO - Started process 15900 to run task
[2024-06-20T16:54:11.726+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1210', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_gzuud9s']
[2024-06-20T16:54:11.748+0000] {standard_task_runner.py:91} INFO - Job 1210: Subtask fetch_player_stats
[2024-06-20T16:54:12.069+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:54:12.609+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:54:12.610+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:54:56.492+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:54:56.492+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 88, in fetch_player_stats
    top_player_stats = top_500_players[columns]
                       ^^^^^^^^^^^^^^^
NameError: name 'top_500_players' is not defined
[2024-06-20T16:54:56.522+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T165411, end_date=20240620T165456
[2024-06-20T16:54:56.532+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 1210 for task fetch_player_stats (name 'top_500_players' is not defined; 15900)
[2024-06-20T16:54:56.574+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-20T16:54:56.610+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:54:56.611+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T17:00:32.628+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T17:00:32.811+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:00:32.865+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:00:32.866+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T17:00:32.925+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T17:00:32.964+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1242', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpnq8l9m9e']
[2024-06-20T17:00:32.978+0000] {standard_task_runner.py:91} INFO - Job 1242: Subtask fetch_player_stats
[2024-06-20T17:00:32.962+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21516) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T17:00:32.980+0000] {standard_task_runner.py:63} INFO - Started process 21746 to run task
[2024-06-20T17:00:33.323+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T17:00:34.008+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T17:00:34.010+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T17:01:16.326+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T17:01:16.326+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 88, in fetch_player_stats
    top_player_stats = top_500_players[columns]
                       ^^^^^^^^^^^^^^^
NameError: name 'top_500_players' is not defined
[2024-06-20T17:01:16.356+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T170032, end_date=20240620T170116
[2024-06-20T17:01:16.367+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 1242 for task fetch_player_stats (name 'top_500_players' is not defined; 21746)
[2024-06-20T17:01:16.378+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-20T17:01:16.401+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T17:40:48.153+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T17:40:48.300+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:40:48.328+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:40:48.333+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T17:40:48.379+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T17:40:48.410+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1269', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_0_ip4ju']
[2024-06-20T17:40:48.417+0000] {standard_task_runner.py:91} INFO - Job 1269: Subtask fetch_player_stats
[2024-06-20T17:40:48.405+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28212) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T17:40:48.419+0000] {standard_task_runner.py:63} INFO - Started process 28413 to run task
[2024-06-20T17:40:48.823+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T17:40:49.615+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T17:40:49.616+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T17:41:34.030+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T17:41:34.030+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T17:41:34.083+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T174048, end_date=20240620T174134
[2024-06-20T17:41:34.111+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T17:41:34.151+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T17:41:34.154+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:03:13.160+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:03:13.368+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:03:13.423+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:03:13.423+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:03:13.511+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:03:13.565+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1310', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp296fk2l6']
[2024-06-20T18:03:13.586+0000] {standard_task_runner.py:91} INFO - Job 1310: Subtask fetch_player_stats
[2024-06-20T18:03:13.567+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=35563) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:03:13.588+0000] {standard_task_runner.py:63} INFO - Started process 35819 to run task
[2024-06-20T18:03:13.920+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:03:14.285+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:03:14.288+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:03:57.706+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:03:57.706+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:03:57.760+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T180313, end_date=20240620T180357
[2024-06-20T18:03:57.785+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:03:57.824+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:03:57.826+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:07:21.625+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:07:21.812+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:07:21.842+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:07:21.842+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:07:21.914+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:07:21.976+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=40588) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:07:21.993+0000] {standard_task_runner.py:63} INFO - Started process 40834 to run task
[2024-06-20T18:07:21.970+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1340', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_m7olm07']
[2024-06-20T18:07:22.000+0000] {standard_task_runner.py:91} INFO - Job 1340: Subtask fetch_player_stats
[2024-06-20T18:07:22.534+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:07:23.191+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:07:23.192+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:08:06.258+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:08:06.258+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:08:06.309+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T180721, end_date=20240620T180806
[2024-06-20T18:08:06.335+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:08:06.381+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:08:06.384+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:12:05.148+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:12:05.347+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:12:05.395+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:12:05.395+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:12:05.479+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:12:05.520+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1375', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpzt2t6enn']
[2024-06-20T18:12:05.547+0000] {standard_task_runner.py:91} INFO - Job 1375: Subtask fetch_player_stats
[2024-06-20T18:12:05.519+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=45562) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:12:05.549+0000] {standard_task_runner.py:63} INFO - Started process 45806 to run task
[2024-06-20T18:12:05.977+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:12:06.601+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:12:06.602+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:12:53.827+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:12:53.828+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:12:53.879+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T181205, end_date=20240620T181253
[2024-06-20T18:12:53.924+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:12:53.962+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:12:53.965+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:16:42.927+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:16:43.071+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:16:43.106+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:16:43.106+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:16:43.162+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:16:43.202+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=49719) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:16:43.208+0000] {standard_task_runner.py:63} INFO - Started process 49942 to run task
[2024-06-20T18:16:43.204+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1410', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpehbq58p8']
[2024-06-20T18:16:43.221+0000] {standard_task_runner.py:91} INFO - Job 1410: Subtask fetch_player_stats
[2024-06-20T18:16:43.551+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:16:44.084+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:16:44.085+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:17:27.800+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:17:27.800+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:17:27.850+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T181643, end_date=20240620T181727
[2024-06-20T18:17:27.878+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:17:27.901+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:23:48.970+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:23:49.249+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:23:49.313+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:23:49.313+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:23:49.409+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:23:49.470+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=56414) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:23:49.470+0000] {standard_task_runner.py:63} INFO - Started process 56665 to run task
[2024-06-20T18:23:49.458+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1447', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_8jcsqox']
[2024-06-20T18:23:49.476+0000] {standard_task_runner.py:91} INFO - Job 1447: Subtask fetch_player_stats
[2024-06-20T18:23:49.878+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:23:50.403+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:23:50.407+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:24:33.631+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:24:33.632+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:24:33.684+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T182349, end_date=20240620T182433
[2024-06-20T18:24:33.743+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:24:33.771+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:27:15.817+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:27:15.996+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:27:16.022+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:27:16.023+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:27:16.069+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:27:16.101+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=61133) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:27:16.112+0000] {standard_task_runner.py:63} INFO - Started process 61373 to run task
[2024-06-20T18:27:16.106+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1480', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpsfhg2ro8']
[2024-06-20T18:27:16.120+0000] {standard_task_runner.py:91} INFO - Job 1480: Subtask fetch_player_stats
[2024-06-20T18:27:16.500+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:27:17.150+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:27:17.151+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:27:59.421+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:27:59.422+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:27:59.493+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T182715, end_date=20240620T182759
[2024-06-20T18:27:59.531+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:27:59.589+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:27:59.591+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:30:34.423+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:30:34.659+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:30:34.714+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:30:34.715+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:30:34.779+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:30:34.816+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=65206) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:30:34.823+0000] {standard_task_runner.py:63} INFO - Started process 65451 to run task
[2024-06-20T18:30:34.824+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1512', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmptfs0x9n3']
[2024-06-20T18:30:34.838+0000] {standard_task_runner.py:91} INFO - Job 1512: Subtask fetch_player_stats
[2024-06-20T18:30:35.227+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:30:35.986+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:30:35.987+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:31:18.926+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:31:18.927+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:31:18.977+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T183034, end_date=20240620T183118
[2024-06-20T18:31:19.014+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:31:19.053+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:31:19.055+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:37:47.928+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:37:48.137+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:37:48.197+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:37:48.197+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:37:48.296+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:37:48.339+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1546', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_t9cluom']
[2024-06-20T18:37:48.346+0000] {standard_task_runner.py:91} INFO - Job 1546: Subtask fetch_player_stats
[2024-06-20T18:37:48.347+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=70968) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:37:48.360+0000] {standard_task_runner.py:63} INFO - Started process 71208 to run task
[2024-06-20T18:37:48.746+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:37:49.183+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:37:49.188+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:38:31.025+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T18:38:31.025+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:38:31.076+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T183748, end_date=20240620T183831
[2024-06-20T18:38:31.111+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:38:31.148+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:38:31.150+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T21:19:27.188+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T21:19:27.424+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:19:27.473+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:19:27.473+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T21:19:27.544+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T21:19:27.610+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1586', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp35lxehjv']
[2024-06-20T21:19:27.638+0000] {standard_task_runner.py:91} INFO - Job 1586: Subtask fetch_player_stats
[2024-06-20T21:19:27.629+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3535) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T21:19:27.641+0000] {standard_task_runner.py:63} INFO - Started process 3792 to run task
[2024-06-20T21:19:28.003+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T21:19:28.589+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T21:19:28.590+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T21:20:12.445+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T21:20:12.445+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T21:20:12.499+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T211927, end_date=20240620T212012
[2024-06-20T21:20:12.538+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T21:20:12.579+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T21:20:12.581+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T21:24:55.368+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T21:24:55.609+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:24:55.671+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:24:55.671+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T21:24:55.747+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T21:24:55.786+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8440) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T21:24:55.784+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1618', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpbe_gjnbl']
[2024-06-20T21:24:55.797+0000] {standard_task_runner.py:91} INFO - Job 1618: Subtask fetch_player_stats
[2024-06-20T21:24:55.787+0000] {standard_task_runner.py:63} INFO - Started process 8688 to run task
[2024-06-20T21:24:56.234+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T21:24:56.857+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T21:24:56.866+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T21:25:44.055+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T21:25:44.055+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T21:25:44.111+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T212455, end_date=20240620T212544
[2024-06-20T21:25:44.164+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T21:25:44.203+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T21:25:44.205+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T22:01:53.866+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T22:01:54.060+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:01:54.119+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:01:54.119+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T22:01:54.210+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T22:01:54.257+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1655', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpgfsp482x']
[2024-06-20T22:01:54.270+0000] {standard_task_runner.py:91} INFO - Job 1655: Subtask fetch_player_stats
[2024-06-20T22:01:54.265+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3161) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T22:01:54.281+0000] {standard_task_runner.py:63} INFO - Started process 3411 to run task
[2024-06-20T22:01:54.779+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T22:01:55.498+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T22:01:55.500+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T22:02:38.804+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T22:02:38.804+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T22:02:38.858+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T220154, end_date=20240620T220238
[2024-06-20T22:02:38.891+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T22:02:38.931+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T22:02:38.933+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T22:07:06.670+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T22:07:06.933+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:07:06.981+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:07:06.982+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T22:07:07.053+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-18 00:00:00+00:00
[2024-06-20T22:07:07.102+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1671', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_oprg2ij']
[2024-06-20T22:07:07.119+0000] {standard_task_runner.py:91} INFO - Job 1671: Subtask fetch_player_stats
[2024-06-20T22:07:07.124+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7585) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T22:07:07.136+0000] {standard_task_runner.py:63} INFO - Started process 7839 to run task
[2024-06-20T22:07:07.558+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T22:07:08.254+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T22:07:08.259+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T22:07:55.711+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-20T22:07:55.712+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T22:07:55.763+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T220706, end_date=20240620T220755
[2024-06-20T22:07:55.818+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T22:07:55.858+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T22:07:55.860+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
