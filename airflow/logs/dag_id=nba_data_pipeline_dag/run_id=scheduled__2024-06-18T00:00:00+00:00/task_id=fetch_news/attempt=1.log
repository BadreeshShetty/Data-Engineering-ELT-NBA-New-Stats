[2024-06-19T00:01:34.419+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:01:34.493+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:01:34.509+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:01:34.510+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:01:34.535+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:01:34.560+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=9131) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:01:34.558+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '565', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp5djqbq7b']
[2024-06-19T00:01:34.564+0000] {standard_task_runner.py:91} INFO - Job 565: Subtask fetch_news
[2024-06-19T00:01:34.564+0000] {standard_task_runner.py:63} INFO - Started process 9210 to run task
[2024-06-19T00:01:34.692+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:01:34.936+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:01:34.937+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:01:35.092+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T00:01:35.092+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:01:35.179+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T000134, end_date=20240619T000135
[2024-06-19T00:01:35.228+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:01:35.294+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:01:35.299+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T00:36:36.150+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:36:36.226+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:36:36.245+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:36:36.246+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:36:36.277+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:36:36.292+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '591', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpck28mswu']
[2024-06-19T00:36:36.299+0000] {standard_task_runner.py:91} INFO - Job 591: Subtask fetch_news
[2024-06-19T00:36:36.298+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3035) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:36:36.302+0000] {standard_task_runner.py:63} INFO - Started process 3128 to run task
[2024-06-19T00:36:36.453+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:36:36.706+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:36:36.707+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:36:37.077+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T00:36:37.078+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:36:37.133+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T003636, end_date=20240619T003637
[2024-06-19T00:36:37.168+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:36:37.210+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:36:37.212+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T00:46:43.977+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T00:46:44.024+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:46:44.032+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T00:46:44.033+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T00:46:44.051+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T00:46:44.071+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '610', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmph81buap6']
[2024-06-19T00:46:44.082+0000] {standard_task_runner.py:91} INFO - Job 610: Subtask fetch_news
[2024-06-19T00:46:44.080+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7779) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T00:46:44.084+0000] {standard_task_runner.py:63} INFO - Started process 7858 to run task
[2024-06-19T00:46:44.241+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T00:46:44.496+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T00:46:44.498+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T00:46:44.692+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T00:46:44.692+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T00:46:44.768+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T004644, end_date=20240619T004644
[2024-06-19T00:46:44.827+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T00:46:44.870+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T00:46:44.872+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:09:20.567+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:09:20.626+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:09:20.634+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:09:20.634+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:09:20.647+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:09:20.666+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '631', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp_lzg83q9']
[2024-06-19T01:09:20.673+0000] {standard_task_runner.py:91} INFO - Job 631: Subtask fetch_news
[2024-06-19T01:09:20.674+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=14305) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:09:20.676+0000] {standard_task_runner.py:63} INFO - Started process 14377 to run task
[2024-06-19T01:09:20.816+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:09:21.032+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:09:21.033+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:09:21.218+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T01:09:21.218+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:09:21.276+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T010920, end_date=20240619T010921
[2024-06-19T01:09:21.305+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:09:21.350+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:09:21.352+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:40:14.754+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:40:14.829+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:40:14.840+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:40:14.840+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:40:14.858+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:40:14.893+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21835) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:40:14.884+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '655', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpffq_jw5c']
[2024-06-19T01:40:14.894+0000] {standard_task_runner.py:91} INFO - Job 655: Subtask fetch_news
[2024-06-19T01:40:14.894+0000] {standard_task_runner.py:63} INFO - Started process 21915 to run task
[2024-06-19T01:40:15.086+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:40:15.301+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:40:15.302+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:40:15.446+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T01:40:15.446+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:40:15.560+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T014014, end_date=20240619T014015
[2024-06-19T01:40:15.609+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:40:15.656+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:40:15.658+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T01:55:36.566+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T01:55:36.641+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:55:36.658+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T01:55:36.658+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T01:55:36.687+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T01:55:36.700+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '671', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp0o7y49k9']
[2024-06-19T01:55:36.710+0000] {standard_task_runner.py:91} INFO - Job 671: Subtask fetch_news
[2024-06-19T01:55:36.709+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=26768) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T01:55:36.711+0000] {standard_task_runner.py:63} INFO - Started process 26838 to run task
[2024-06-19T01:55:36.885+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T01:55:37.171+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T01:55:37.176+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T01:55:37.348+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T01:55:37.348+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T01:55:37.435+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T015536, end_date=20240619T015537
[2024-06-19T01:55:37.463+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T01:55:37.506+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T01:55:37.512+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T04:28:50.123+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T04:28:50.186+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T04:28:50.194+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T04:28:50.195+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T04:28:50.209+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T04:28:50.237+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '690', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpm2k1pmrs']
[2024-06-19T04:28:50.251+0000] {standard_task_runner.py:91} INFO - Job 690: Subtask fetch_news
[2024-06-19T04:28:50.250+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3301) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T04:28:50.255+0000] {standard_task_runner.py:63} INFO - Started process 3413 to run task
[2024-06-19T04:28:50.368+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T04:28:50.575+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T04:28:50.576+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T04:28:51.041+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T04:28:51.041+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T04:28:51.097+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T042850, end_date=20240619T042851
[2024-06-19T04:28:51.124+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T04:28:51.166+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T04:28:51.168+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T13:53:57.708+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T13:53:57.775+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:53:57.783+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T13:53:57.784+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T13:53:57.800+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T13:53:57.817+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '707', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpi3f7xdmh']
[2024-06-19T13:53:57.824+0000] {standard_task_runner.py:91} INFO - Job 707: Subtask fetch_news
[2024-06-19T13:53:57.822+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=5132) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T13:53:57.828+0000] {standard_task_runner.py:63} INFO - Started process 5208 to run task
[2024-06-19T13:53:57.969+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T13:53:58.175+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T13:53:58.176+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T13:53:58.719+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T13:53:58.720+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T13:53:58.769+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T135357, end_date=20240619T135358
[2024-06-19T13:53:58.808+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T13:53:58.847+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T13:53:58.848+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T17:10:28.191+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T17:10:28.285+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:10:28.298+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:10:28.299+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T17:10:28.335+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T17:10:28.358+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '727', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpe5b4zf2q']
[2024-06-19T17:10:28.366+0000] {standard_task_runner.py:91} INFO - Job 727: Subtask fetch_news
[2024-06-19T17:10:28.369+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3925) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T17:10:28.375+0000] {standard_task_runner.py:63} INFO - Started process 4018 to run task
[2024-06-19T17:10:28.614+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T17:10:28.990+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T17:10:28.991+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T17:10:29.365+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T17:10:29.366+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T17:10:29.419+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T171028, end_date=20240619T171029
[2024-06-19T17:10:29.447+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T17:10:29.490+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T17:10:29.492+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T17:25:38.786+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T17:25:38.861+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:25:38.874+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T17:25:38.874+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T17:25:38.890+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T17:25:38.911+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '748', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpgjvwu1tk']
[2024-06-19T17:25:38.923+0000] {standard_task_runner.py:91} INFO - Job 748: Subtask fetch_news
[2024-06-19T17:25:38.922+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8460) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T17:25:38.927+0000] {standard_task_runner.py:63} INFO - Started process 8559 to run task
[2024-06-19T17:25:39.107+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T17:25:39.443+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T17:25:39.448+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T17:25:39.773+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T17:25:39.774+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T17:25:39.847+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T172538, end_date=20240619T172539
[2024-06-19T17:25:39.872+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T17:25:39.914+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T17:25:39.916+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-19T21:12:29.028+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-19T21:12:29.143+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T21:12:29.167+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-19T21:12:29.167+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-19T21:12:29.208+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-19T21:12:29.220+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '769', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpi2d5waah']
[2024-06-19T21:12:29.233+0000] {standard_task_runner.py:91} INFO - Job 769: Subtask fetch_news
[2024-06-19T21:12:29.237+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=4322) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-19T21:12:29.238+0000] {standard_task_runner.py:63} INFO - Started process 4423 to run task
[2024-06-19T21:12:29.457+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-19T21:12:29.796+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-19T21:12:29.799+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-19T21:12:30.261+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-19T21:12:30.261+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-19T21:12:30.316+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240619T211229, end_date=20240619T211230
[2024-06-19T21:12:30.349+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-19T21:12:30.390+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-19T21:12:30.393+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:34:05.450+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:34:05.570+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:34:05.594+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:34:05.595+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:34:05.636+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:34:05.675+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '799', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpwb9hwu2s']
[2024-06-20T11:34:05.685+0000] {standard_task_runner.py:91} INFO - Job 799: Subtask fetch_news
[2024-06-20T11:34:05.679+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3253) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:34:05.690+0000] {standard_task_runner.py:63} INFO - Started process 3385 to run task
[2024-06-20T11:34:05.897+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:34:06.305+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:34:06.307+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:34:07.081+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T11:34:07.081+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:34:07.328+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T113405, end_date=20240620T113407
[2024-06-20T11:34:07.459+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:34:07.626+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T11:34:07.631+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:40:16.216+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:40:16.423+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:40:16.479+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:40:16.480+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:40:16.559+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:40:16.624+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7631) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:40:16.637+0000] {standard_task_runner.py:63} INFO - Started process 7857 to run task
[2024-06-20T11:40:16.626+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '829', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpfjw80xag']
[2024-06-20T11:40:16.639+0000] {standard_task_runner.py:91} INFO - Job 829: Subtask fetch_news
[2024-06-20T11:40:17.134+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:40:17.708+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:40:17.710+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:40:18.155+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T11:40:18.156+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:40:18.392+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T114016, end_date=20240620T114018
[2024-06-20T11:40:18.485+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:40:18.556+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T11:40:18.563+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T11:52:18.019+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T11:52:18.263+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:52:18.315+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T11:52:18.320+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T11:52:18.412+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T11:52:18.458+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '867', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphxnswr8l']
[2024-06-20T11:52:18.483+0000] {standard_task_runner.py:91} INFO - Job 867: Subtask fetch_news
[2024-06-20T11:52:18.482+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=14549) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T11:52:18.492+0000] {standard_task_runner.py:63} INFO - Started process 14791 to run task
[2024-06-20T11:52:18.920+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T11:52:19.662+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T11:52:19.668+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T11:52:19.987+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T11:52:19.996+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T11:52:20.118+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T115218, end_date=20240620T115220
[2024-06-20T11:52:20.305+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T11:52:20.437+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:12:14.468+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:12:14.762+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:12:14.809+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:12:14.811+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:12:14.895+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:12:14.919+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=22526) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:12:14.929+0000] {standard_task_runner.py:63} INFO - Started process 22754 to run task
[2024-06-20T12:12:14.921+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '914', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpmk5x_qfv']
[2024-06-20T12:12:14.934+0000] {standard_task_runner.py:91} INFO - Job 914: Subtask fetch_news
[2024-06-20T12:12:15.395+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:12:16.319+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:12:16.333+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:12:16.640+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:12:16.642+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:12:16.881+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T121214, end_date=20240620T121216
[2024-06-20T12:12:16.996+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:12:17.174+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:12:17.186+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:20:39.199+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:20:39.430+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:20:39.495+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:20:39.496+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:20:39.579+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:20:39.655+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28708) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:20:39.672+0000] {standard_task_runner.py:63} INFO - Started process 28952 to run task
[2024-06-20T12:20:39.645+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '951', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp6dg1cr5y']
[2024-06-20T12:20:39.675+0000] {standard_task_runner.py:91} INFO - Job 951: Subtask fetch_news
[2024-06-20T12:20:40.185+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:20:40.812+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:20:40.827+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:20:41.217+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:20:41.220+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:20:41.404+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T122039, end_date=20240620T122041
[2024-06-20T12:20:41.479+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:20:41.635+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:20:41.645+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:37:40.554+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:37:40.716+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:37:40.752+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:37:40.761+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:37:40.835+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:37:40.889+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=34272) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:37:40.900+0000] {standard_task_runner.py:63} INFO - Started process 34482 to run task
[2024-06-20T12:37:40.903+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '978', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp3f6bdkx8']
[2024-06-20T12:37:40.922+0000] {standard_task_runner.py:91} INFO - Job 978: Subtask fetch_news
[2024-06-20T12:37:41.322+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:37:42.065+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:37:42.066+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:37:42.443+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:37:42.444+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:37:42.632+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T123740, end_date=20240620T123742
[2024-06-20T12:37:42.707+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:37:42.826+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:37:42.833+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:39:34.265+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:39:34.544+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:39:34.604+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:39:34.606+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:39:34.680+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:39:34.743+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=36873) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:39:34.752+0000] {standard_task_runner.py:63} INFO - Started process 37126 to run task
[2024-06-20T12:39:34.748+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1002', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmptfbtuef4']
[2024-06-20T12:39:34.759+0000] {standard_task_runner.py:91} INFO - Job 1002: Subtask fetch_news
[2024-06-20T12:39:35.206+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:39:35.967+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:39:35.973+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:39:36.383+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:39:36.385+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:39:36.518+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T123934, end_date=20240620T123936
[2024-06-20T12:39:36.617+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:39:36.687+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:49:08.106+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:49:08.362+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:49:08.416+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:49:08.416+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:49:08.506+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:49:08.572+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1038', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp8hbefj8u']
[2024-06-20T12:49:08.586+0000] {standard_task_runner.py:91} INFO - Job 1038: Subtask fetch_news
[2024-06-20T12:49:08.572+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=42694) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:49:08.587+0000] {standard_task_runner.py:63} INFO - Started process 42944 to run task
[2024-06-20T12:49:09.101+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:49:10.065+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:49:10.066+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:49:10.720+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:49:10.721+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:49:10.905+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T124908, end_date=20240620T124910
[2024-06-20T12:49:11.173+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:49:11.378+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:49:11.387+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T12:54:36.742+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T12:54:36.978+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:54:37.036+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T12:54:37.037+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T12:54:37.153+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T12:54:37.234+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=48842) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T12:54:37.250+0000] {standard_task_runner.py:63} INFO - Started process 49003 to run task
[2024-06-20T12:54:37.225+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1075', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpdkigonwe']
[2024-06-20T12:54:37.255+0000] {standard_task_runner.py:91} INFO - Job 1075: Subtask fetch_news
[2024-06-20T12:54:37.726+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T12:54:38.298+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T12:54:38.309+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T12:54:38.639+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T12:54:38.639+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T12:54:38.847+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T125436, end_date=20240620T125438
[2024-06-20T12:54:38.941+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T12:54:39.068+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T12:54:39.076+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T13:06:19.164+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T13:06:19.345+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T13:06:19.374+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T13:06:19.375+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T13:06:19.424+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T13:06:19.459+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=55104) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T13:06:19.465+0000] {standard_task_runner.py:63} INFO - Started process 55345 to run task
[2024-06-20T13:06:19.463+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1110', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpy1ump7na']
[2024-06-20T13:06:19.467+0000] {standard_task_runner.py:91} INFO - Job 1110: Subtask fetch_news
[2024-06-20T13:06:19.910+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T13:06:20.659+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T13:06:20.660+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T13:06:21.119+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T13:06:21.120+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T13:06:21.331+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T130619, end_date=20240620T130621
[2024-06-20T13:06:21.435+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T13:06:21.701+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T13:06:21.712+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:34:08.914+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:34:09.057+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:34:09.121+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:34:09.121+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:34:09.198+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:34:09.244+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1144', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp2y8ktold']
[2024-06-20T16:34:09.263+0000] {standard_task_runner.py:91} INFO - Job 1144: Subtask fetch_news
[2024-06-20T16:34:09.267+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=4418) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:34:09.276+0000] {standard_task_runner.py:63} INFO - Started process 4656 to run task
[2024-06-20T16:34:09.739+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:34:10.496+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:34:10.497+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:34:11.011+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T16:34:11.015+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:34:11.172+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T163409, end_date=20240620T163411
[2024-06-20T16:34:11.254+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T16:34:11.429+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:34:11.432+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:43:38.723+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:43:38.950+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:43:39.010+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:43:39.010+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:43:39.074+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:43:39.092+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=10086) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:43:39.104+0000] {standard_task_runner.py:63} INFO - Started process 10332 to run task
[2024-06-20T16:43:39.097+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1182', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp68ctu_7t']
[2024-06-20T16:43:39.108+0000] {standard_task_runner.py:91} INFO - Job 1182: Subtask fetch_news
[2024-06-20T16:43:39.534+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:43:40.108+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:43:40.109+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:43:40.487+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T16:43:40.490+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:43:40.634+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T164338, end_date=20240620T164340
[2024-06-20T16:43:40.674+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T16:43:40.796+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T16:43:40.800+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T16:54:11.015+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T16:54:11.209+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:54:11.264+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T16:54:11.264+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T16:54:11.327+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T16:54:11.384+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=15689) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T16:54:11.400+0000] {standard_task_runner.py:63} INFO - Started process 15846 to run task
[2024-06-20T16:54:11.392+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1207', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphsx9fe2g']
[2024-06-20T16:54:11.410+0000] {standard_task_runner.py:91} INFO - Job 1207: Subtask fetch_news
[2024-06-20T16:54:11.740+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T16:54:12.245+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T16:54:12.248+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T16:54:12.720+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T16:54:12.720+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T16:54:12.879+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T165411, end_date=20240620T165412
[2024-06-20T16:54:12.975+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T16:54:13.050+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T17:00:32.631+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T17:00:32.803+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:00:32.842+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:00:32.842+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T17:00:32.906+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T17:00:32.947+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21513) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T17:00:32.954+0000] {standard_task_runner.py:63} INFO - Started process 21743 to run task
[2024-06-20T17:00:32.949+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1241', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpwp4iatyy']
[2024-06-20T17:00:32.959+0000] {standard_task_runner.py:91} INFO - Job 1241: Subtask fetch_news
[2024-06-20T17:00:33.264+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T17:00:33.893+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T17:00:33.894+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T17:00:34.299+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T17:00:34.302+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T17:00:34.501+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T170032, end_date=20240620T170034
[2024-06-20T17:00:34.600+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T17:00:34.802+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T17:00:34.808+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T17:40:48.353+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T17:40:48.605+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:40:48.680+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T17:40:48.682+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T17:40:48.783+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T17:40:48.845+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28213) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T17:40:48.841+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1270', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpqsjda7fo']
[2024-06-20T17:40:48.864+0000] {standard_task_runner.py:91} INFO - Job 1270: Subtask fetch_news
[2024-06-20T17:40:48.866+0000] {standard_task_runner.py:63} INFO - Started process 28431 to run task
[2024-06-20T17:40:49.205+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T17:40:49.926+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T17:40:49.930+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T17:40:50.319+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T17:40:50.319+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T17:40:50.477+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T174048, end_date=20240620T174050
[2024-06-20T17:40:50.558+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T17:40:50.696+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T17:40:50.701+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:03:12.781+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:03:12.986+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:03:13.029+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:03:13.029+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:03:13.110+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:03:13.168+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=35565) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:03:13.171+0000] {standard_task_runner.py:63} INFO - Started process 35796 to run task
[2024-06-20T18:03:13.162+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1308', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpigo6uela']
[2024-06-20T18:03:13.180+0000] {standard_task_runner.py:91} INFO - Job 1308: Subtask fetch_news
[2024-06-20T18:03:13.418+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:03:13.817+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:03:13.825+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:03:15.170+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:03:15.170+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:03:15.224+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T180312, end_date=20240620T180315
[2024-06-20T18:03:15.263+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:03:15.304+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:03:15.306+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:07:21.732+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:07:21.904+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:07:21.966+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:07:21.967+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:07:22.049+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:07:22.095+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=40590) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:07:22.106+0000] {standard_task_runner.py:63} INFO - Started process 40845 to run task
[2024-06-20T18:07:22.090+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1345', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpw4yp51rj']
[2024-06-20T18:07:22.120+0000] {standard_task_runner.py:91} INFO - Job 1345: Subtask fetch_news
[2024-06-20T18:07:22.687+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:07:23.319+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:07:23.320+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:07:24.166+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:07:24.167+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:07:24.333+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T180721, end_date=20240620T180724
[2024-06-20T18:07:24.408+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:07:24.487+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:07:24.494+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:12:04.972+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:12:05.163+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:12:05.221+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:12:05.222+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:12:05.299+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:12:05.357+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=45563) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:12:05.366+0000] {standard_task_runner.py:63} INFO - Started process 45799 to run task
[2024-06-20T18:12:05.361+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1374', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp1eu3x__x']
[2024-06-20T18:12:05.373+0000] {standard_task_runner.py:91} INFO - Job 1374: Subtask fetch_news
[2024-06-20T18:12:05.672+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:12:06.235+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:12:06.237+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:12:07.162+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:12:07.165+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:12:07.262+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T181205, end_date=20240620T181207
[2024-06-20T18:12:07.299+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:12:07.340+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:12:07.342+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:16:42.944+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:16:43.132+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:16:43.180+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:16:43.180+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:16:43.258+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:16:43.314+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=49721) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:16:43.309+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1407', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpfvq0g1my']
[2024-06-20T18:16:43.317+0000] {standard_task_runner.py:91} INFO - Job 1407: Subtask fetch_news
[2024-06-20T18:16:43.334+0000] {standard_task_runner.py:63} INFO - Started process 49949 to run task
[2024-06-20T18:16:43.796+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:16:44.444+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:16:44.445+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:16:45.344+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:16:45.345+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:16:45.397+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T181643, end_date=20240620T181645
[2024-06-20T18:16:45.429+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:16:45.499+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:16:45.505+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:23:48.453+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:23:48.651+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:23:48.698+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:23:48.698+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:23:48.747+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:23:48.807+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=56413) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:23:48.819+0000] {standard_task_runner.py:63} INFO - Started process 56633 to run task
[2024-06-20T18:23:48.806+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1444', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpi_z2prc6']
[2024-06-20T18:23:48.828+0000] {standard_task_runner.py:91} INFO - Job 1444: Subtask fetch_news
[2024-06-20T18:23:49.091+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:23:49.745+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:23:49.748+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:23:50.740+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:23:50.749+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:23:50.930+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T182348, end_date=20240620T182350
[2024-06-20T18:23:51.043+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:23:51.184+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:27:15.620+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:27:15.773+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:27:15.821+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:27:15.822+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:27:15.879+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:27:15.930+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=61134) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:27:15.931+0000] {standard_task_runner.py:63} INFO - Started process 61366 to run task
[2024-06-20T18:27:15.932+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1478', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpkd8_ir0c']
[2024-06-20T18:27:15.945+0000] {standard_task_runner.py:91} INFO - Job 1478: Subtask fetch_news
[2024-06-20T18:27:16.333+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:27:17.006+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:27:17.007+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:27:17.657+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:27:17.658+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:27:17.879+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T182715, end_date=20240620T182717
[2024-06-20T18:27:17.991+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:27:18.106+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:27:18.117+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:30:34.383+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:30:34.556+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:30:34.604+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:30:34.605+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:30:34.655+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:30:34.696+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=65207) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:30:34.704+0000] {standard_task_runner.py:63} INFO - Started process 65445 to run task
[2024-06-20T18:30:34.713+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1511', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmps2l8l2z6']
[2024-06-20T18:30:34.735+0000] {standard_task_runner.py:91} INFO - Job 1511: Subtask fetch_news
[2024-06-20T18:30:35.132+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:30:35.806+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:30:35.808+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:30:37.308+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:30:37.308+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:30:37.476+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T183034, end_date=20240620T183037
[2024-06-20T18:30:37.562+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:30:37.694+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T18:30:37.698+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T18:37:48.084+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T18:37:48.209+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:37:48.227+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T18:37:48.229+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T18:37:48.266+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T18:37:48.304+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=70969) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T18:37:48.299+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1549', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp58wrh75q']
[2024-06-20T18:37:48.309+0000] {standard_task_runner.py:91} INFO - Job 1549: Subtask fetch_news
[2024-06-20T18:37:48.305+0000] {standard_task_runner.py:63} INFO - Started process 71206 to run task
[2024-06-20T18:37:48.748+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T18:37:49.356+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T18:37:49.357+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T18:37:49.746+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T18:37:49.749+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T18:37:49.864+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T183748, end_date=20240620T183749
[2024-06-20T18:37:49.910+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T18:37:49.984+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T21:19:26.939+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T21:19:27.092+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:19:27.131+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:19:27.131+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T21:19:27.173+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T21:19:27.203+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1582', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpoz6gvo8h']
[2024-06-20T21:19:27.221+0000] {standard_task_runner.py:91} INFO - Job 1582: Subtask fetch_news
[2024-06-20T21:19:27.220+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3533) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T21:19:27.230+0000] {standard_task_runner.py:63} INFO - Started process 3771 to run task
[2024-06-20T21:19:27.627+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T21:19:28.210+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T21:19:28.223+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T21:19:28.917+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T21:19:28.917+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T21:19:29.129+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T211927, end_date=20240620T211929
[2024-06-20T21:19:29.200+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T21:19:29.328+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T21:19:29.333+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T21:24:55.343+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T21:24:55.582+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:24:55.639+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T21:24:55.639+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T21:24:55.720+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T21:24:55.781+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8441) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T21:24:55.793+0000] {standard_task_runner.py:63} INFO - Started process 8687 to run task
[2024-06-20T21:24:55.782+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1617', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphiw_96wq']
[2024-06-20T21:24:55.796+0000] {standard_task_runner.py:91} INFO - Job 1617: Subtask fetch_news
[2024-06-20T21:24:56.293+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T21:24:56.986+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T21:24:56.989+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T21:24:57.424+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T21:24:57.425+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T21:24:57.588+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T212455, end_date=20240620T212457
[2024-06-20T21:24:57.653+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T21:24:57.713+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T21:24:57.719+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T22:01:53.600+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T22:01:53.819+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:01:53.849+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:01:53.849+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T22:01:53.887+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T22:01:53.934+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1650', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpy3mmvl8d']
[2024-06-20T22:01:53.958+0000] {standard_task_runner.py:91} INFO - Job 1650: Subtask fetch_news
[2024-06-20T22:01:53.954+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3160) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T22:01:53.963+0000] {standard_task_runner.py:63} INFO - Started process 3398 to run task
[2024-06-20T22:01:54.387+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T22:01:55.007+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T22:01:55.013+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T22:01:55.701+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T22:01:55.706+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T22:01:55.858+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T220153, end_date=20240620T220155
[2024-06-20T22:01:55.938+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T22:01:56.051+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-20T22:07:06.417+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-20T22:07:06.623+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:07:06.681+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [queued]>
[2024-06-20T22:07:06.682+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-20T22:07:06.788+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_news> on 2024-06-18 00:00:00+00:00
[2024-06-20T22:07:06.868+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_news', 'scheduled__2024-06-18T00:00:00+00:00', '--job-id', '1669', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpzkna592f']
[2024-06-20T22:07:06.881+0000] {standard_task_runner.py:91} INFO - Job 1669: Subtask fetch_news
[2024-06-20T22:07:06.880+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7587) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-20T22:07:06.889+0000] {standard_task_runner.py:63} INFO - Started process 7828 to run task
[2024-06-20T22:07:07.311+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_news scheduled__2024-06-18T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-20T22:07:08.001+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_news' AIRFLOW_CTX_EXECUTION_DATE='2024-06-18T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-18T00:00:00+00:00'
[2024-06-20T22:07:08.002+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-20T22:07:08.453+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_news.parquet
[2024-06-20T22:07:08.453+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-20T22:07:08.590+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_news, run_id=scheduled__2024-06-18T00:00:00+00:00, execution_date=20240618T000000, start_date=20240620T220706, end_date=20240620T220708
[2024-06-20T22:07:08.671+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-20T22:07:08.769+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-20T22:07:08.774+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
