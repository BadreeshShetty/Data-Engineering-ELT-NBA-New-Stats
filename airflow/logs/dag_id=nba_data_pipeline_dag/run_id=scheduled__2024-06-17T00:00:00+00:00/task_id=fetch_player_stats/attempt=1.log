[2024-06-18T21:04:22.083+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:04:22.191+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:04:22.201+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:04:22.201+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:04:22.223+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:04:22.257+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '311', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmparopvcwu']
[2024-06-18T21:04:22.273+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=10714) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:04:22.278+0000] {standard_task_runner.py:63} INFO - Started process 10934 to run task
[2024-06-18T21:04:22.276+0000] {standard_task_runner.py:91} INFO - Job 311: Subtask fetch_player_stats
[2024-06-18T21:04:22.611+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:04:23.059+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:04:23.062+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:05:06.829+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T21:05:06.830+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:05:06.888+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T210422, end_date=20240618T210506
[2024-06-18T21:05:06.939+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T21:05:06.982+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T21:05:06.984+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T21:14:46.782+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:14:46.865+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:14:46.879+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:14:46.880+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:14:46.904+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:14:46.935+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '330', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpb2ilqgdp']
[2024-06-18T21:14:46.936+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=15381) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:14:46.946+0000] {standard_task_runner.py:63} INFO - Started process 15455 to run task
[2024-06-18T21:14:46.947+0000] {standard_task_runner.py:91} INFO - Job 330: Subtask fetch_player_stats
[2024-06-18T21:14:47.155+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:14:47.472+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:14:47.473+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:15:07.280+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-06-18T21:15:07.281+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T21:15:07.288+0000] {process_utils.py:132} INFO - Sending 15 to group 15455. PIDs of all processes in the group: [15455]
[2024-06-18T21:15:07.289+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 15455
[2024-06-18T21:15:07.289+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-06-18T21:15:07.289+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:15:07.314+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 78, in fetch_player_stats
    time.sleep(1)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-06-18T21:15:07.321+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T211446, end_date=20240618T211507
[2024-06-18T21:15:07.338+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 330 for task fetch_player_stats ((psycopg2.errors.ForeignKeyViolation) insert or update on table "task_fail" violates foreign key constraint "task_fail_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(nba_data_pipeline_dag, fetch_player_stats, scheduled__2024-06-17T00:00:00+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(run_id)s, %(map_index)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'fetch_player_stats', 'dag_id': 'nba_data_pipeline_dag', 'run_id': 'scheduled__2024-06-17T00:00:00+00:00', 'map_index': -1, 'start_date': datetime.datetime(2024, 6, 18, 21, 14, 46, 866404, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2024, 6, 18, 21, 15, 7, 320621, tzinfo=Timezone('UTC')), 'duration': 20}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 15455)
[2024-06-18T21:15:07.382+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=15455, status='terminated', exitcode=1, started='21:14:46') (15455) terminated with exit code 1
[2024-06-18T21:15:48.639+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:15:48.717+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:15:48.735+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:15:48.735+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:15:48.767+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:15:48.786+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=17399) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:15:48.790+0000] {standard_task_runner.py:63} INFO - Started process 17476 to run task
[2024-06-18T21:15:48.787+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '346', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmphl4_31ex']
[2024-06-18T21:15:48.793+0000] {standard_task_runner.py:91} INFO - Job 346: Subtask fetch_player_stats
[2024-06-18T21:15:48.972+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:15:49.241+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:15:49.246+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:16:34.779+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T21:16:34.780+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:16:34.837+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T211548, end_date=20240618T211634
[2024-06-18T21:16:34.883+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T21:16:34.926+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T21:16:34.928+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T21:21:09.268+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:21:09.481+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:21:09.504+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:21:09.507+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:21:09.573+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:21:09.620+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '379', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpk7rb477b']
[2024-06-18T21:21:09.640+0000] {standard_task_runner.py:91} INFO - Job 379: Subtask fetch_player_stats
[2024-06-18T21:21:09.644+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21829) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:21:09.650+0000] {standard_task_runner.py:63} INFO - Started process 22059 to run task
[2024-06-18T21:21:10.051+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:21:10.492+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:21:10.494+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:21:55.730+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T21:21:55.730+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:21:55.787+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T212109, end_date=20240618T212155
[2024-06-18T21:21:55.832+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T21:21:55.877+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T21:21:55.879+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T21:46:11.463+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:46:11.543+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:46:11.572+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:46:11.573+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:46:11.605+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:46:11.633+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28485) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:46:11.640+0000] {standard_task_runner.py:63} INFO - Started process 28566 to run task
[2024-06-18T21:46:11.635+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '403', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp3wxgbv82']
[2024-06-18T21:46:11.642+0000] {standard_task_runner.py:91} INFO - Job 403: Subtask fetch_player_stats
[2024-06-18T21:46:11.842+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:46:12.067+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:46:12.070+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:47:01.650+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T21:47:01.651+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:47:01.711+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T214611, end_date=20240618T214701
[2024-06-18T21:47:01.770+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T21:47:01.816+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T21:47:01.819+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T21:48:38.774+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T21:48:38.847+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:48:38.857+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T21:48:38.858+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T21:48:38.878+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T21:48:38.899+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '413', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpd3zb20pd']
[2024-06-18T21:48:38.908+0000] {standard_task_runner.py:91} INFO - Job 413: Subtask fetch_player_stats
[2024-06-18T21:48:38.905+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=30463) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T21:48:38.910+0000] {standard_task_runner.py:63} INFO - Started process 30569 to run task
[2024-06-18T21:48:39.099+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T21:48:39.505+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T21:48:39.508+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T21:49:30.444+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T21:49:30.445+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T21:49:30.501+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T214838, end_date=20240618T214930
[2024-06-18T21:49:30.576+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T21:49:30.617+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T21:49:30.620+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T22:06:46.143+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T22:06:46.205+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:06:46.216+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:06:46.216+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T22:06:46.236+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T22:06:46.262+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '453', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp9bhjrzkr']
[2024-06-18T22:06:46.270+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=40090) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T22:06:46.271+0000] {standard_task_runner.py:91} INFO - Job 453: Subtask fetch_player_stats
[2024-06-18T22:06:46.271+0000] {standard_task_runner.py:63} INFO - Started process 40198 to run task
[2024-06-18T22:06:46.429+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T22:06:46.667+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:06:46.668+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T22:07:29.786+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T22:07:29.787+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T22:07:29.842+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T220646, end_date=20240618T220729
[2024-06-18T22:07:29.871+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T22:07:29.913+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T22:07:29.915+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T22:10:41.553+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T22:10:41.597+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:10:41.606+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:10:41.606+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T22:10:41.624+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T22:10:41.648+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=42745) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T22:10:41.652+0000] {standard_task_runner.py:63} INFO - Started process 42818 to run task
[2024-06-18T22:10:41.650+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '466', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpmqk32xbp']
[2024-06-18T22:10:41.660+0000] {standard_task_runner.py:91} INFO - Job 466: Subtask fetch_player_stats
[2024-06-18T22:10:41.835+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T22:10:42.124+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:10:42.126+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T22:11:27.907+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T22:11:27.907+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T22:11:27.962+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T221041, end_date=20240618T221127
[2024-06-18T22:11:28.003+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T22:11:28.045+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T22:11:28.047+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T22:14:42.889+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T22:14:43.028+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:14:43.058+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:14:43.059+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T22:14:43.095+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T22:14:43.131+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '481', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp4_rczrwf']
[2024-06-18T22:14:43.147+0000] {standard_task_runner.py:91} INFO - Job 481: Subtask fetch_player_stats
[2024-06-18T22:14:43.144+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=45589) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T22:14:43.153+0000] {standard_task_runner.py:63} INFO - Started process 45786 to run task
[2024-06-18T22:14:43.386+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T22:14:43.805+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:14:43.814+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T22:15:25.889+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T22:15:25.889+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T22:15:25.913+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 486, in _execute_task
    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3197, in xcom_push
    XCom.set(
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/xcom.py", line 223, in set
    raise ValueError(f"DAG run not found on DAG {dag_id!r} with ID {run_id!r}")
ValueError: DAG run not found on DAG 'nba_data_pipeline_dag' with ID 'scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:15:25.942+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T221443, end_date=20240618T221525
[2024-06-18T22:15:25.955+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 481 for task fetch_player_stats ((psycopg2.errors.ForeignKeyViolation) insert or update on table "task_fail" violates foreign key constraint "task_fail_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(nba_data_pipeline_dag, fetch_player_stats, scheduled__2024-06-17T00:00:00+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(run_id)s, %(map_index)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'fetch_player_stats', 'dag_id': 'nba_data_pipeline_dag', 'run_id': 'scheduled__2024-06-17T00:00:00+00:00', 'map_index': -1, 'start_date': datetime.datetime(2024, 6, 18, 22, 14, 43, 29357, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2024, 6, 18, 22, 15, 25, 942261, tzinfo=Timezone('UTC')), 'duration': 42}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 45786)
[2024-06-18T22:19:23.912+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T22:19:23.966+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:19:23.979+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:19:23.979+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T22:19:23.996+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T22:19:24.028+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '495', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpcv00iwz2']
[2024-06-18T22:19:24.033+0000] {standard_task_runner.py:91} INFO - Job 495: Subtask fetch_player_stats
[2024-06-18T22:19:24.040+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=48850) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T22:19:24.043+0000] {standard_task_runner.py:63} INFO - Started process 48922 to run task
[2024-06-18T22:19:24.194+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T22:19:24.537+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:19:24.538+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T22:20:09.053+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T22:20:09.053+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T22:20:09.113+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T221923, end_date=20240618T222009
[2024-06-18T22:20:09.138+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T22:20:09.183+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T22:20:09.185+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T22:34:28.549+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T22:34:28.629+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:34:28.646+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T22:34:28.648+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T22:34:28.679+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T22:34:28.700+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '505', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpl57aa_0x']
[2024-06-18T22:34:28.706+0000] {standard_task_runner.py:91} INFO - Job 505: Subtask fetch_player_stats
[2024-06-18T22:34:28.710+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=52254) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T22:34:28.713+0000] {standard_task_runner.py:63} INFO - Started process 52356 to run task
[2024-06-18T22:34:28.907+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T22:34:29.283+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T22:34:29.289+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T22:34:43.977+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-06-18T22:34:43.978+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T22:34:43.992+0000] {process_utils.py:132} INFO - Sending 15 to group 52356. PIDs of all processes in the group: [52356]
[2024-06-18T22:34:43.993+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 52356
[2024-06-18T22:34:43.993+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-06-18T22:34:43.994+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T22:34:44.021+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/dags/nba_data_pipeline_dag.py", line 81, in fetch_player_stats
    time.sleep(1)
  File "/home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-06-18T22:34:44.026+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T223428, end_date=20240618T223444
[2024-06-18T22:34:44.041+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 505 for task fetch_player_stats ((psycopg2.errors.ForeignKeyViolation) insert or update on table "task_fail" violates foreign key constraint "task_fail_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(nba_data_pipeline_dag, fetch_player_stats, scheduled__2024-06-17T00:00:00+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(run_id)s, %(map_index)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'fetch_player_stats', 'dag_id': 'nba_data_pipeline_dag', 'run_id': 'scheduled__2024-06-17T00:00:00+00:00', 'map_index': -1, 'start_date': datetime.datetime(2024, 6, 18, 22, 34, 28, 631224, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2024, 6, 18, 22, 34, 44, 25292, tzinfo=Timezone('UTC')), 'duration': 15}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 52356)
[2024-06-18T22:34:44.091+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=52356, status='terminated', exitcode=1, started='22:34:28') (52356) terminated with exit code 1
[2024-06-18T23:47:38.041+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T23:47:38.098+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T23:47:38.111+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T23:47:38.114+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T23:47:38.148+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_player_stats> on 2024-06-17 00:00:00+00:00
[2024-06-18T23:47:38.164+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline_dag', 'fetch_player_stats', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '545', '--raw', '--subdir', 'DAGS_FOLDER/nba_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpet7r7qxk']
[2024-06-18T23:47:38.171+0000] {standard_task_runner.py:91} INFO - Job 545: Subtask fetch_player_stats
[2024-06-18T23:47:38.173+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3470) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T23:47:38.174+0000] {standard_task_runner.py:63} INFO - Started process 3558 to run task
[2024-06-18T23:47:38.335+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline_dag.fetch_player_stats scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T23:47:38.666+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='fetch_player_stats' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T23:47:38.667+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T23:48:25.015+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/player_stats.csv
[2024-06-18T23:48:25.015+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T23:48:25.070+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline_dag, task_id=fetch_player_stats, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T234738, end_date=20240618T234825
[2024-06-18T23:48:25.097+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T23:48:25.139+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T23:48:25.141+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
