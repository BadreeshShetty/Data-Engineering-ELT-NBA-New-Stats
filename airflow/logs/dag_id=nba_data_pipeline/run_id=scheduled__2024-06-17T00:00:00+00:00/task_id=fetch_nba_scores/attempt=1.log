[2024-06-18T16:33:22.291+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T16:33:22.366+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:33:22.381+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:33:22.381+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T16:33:22.400+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T16:33:22.422+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpqr1upifb']
[2024-06-18T16:33:22.441+0000] {standard_task_runner.py:91} INFO - Job 80: Subtask fetch_nba_scores
[2024-06-18T16:33:22.438+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1751) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T16:33:22.443+0000] {standard_task_runner.py:63} INFO - Started process 1832 to run task
[2024-06-18T16:33:22.606+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T16:33:22.847+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T16:33:22.851+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T16:33:22.954+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T16:33:22.955+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T16:33:23.013+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T163322, end_date=20240618T163323
[2024-06-18T16:33:23.036+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T16:33:23.064+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/models/baseoperator.py:1297 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2024-06-18T16:33:23.095+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T16:33:23.097+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T16:42:18.584+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T16:42:18.671+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:42:18.688+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:42:18.688+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T16:42:18.706+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T16:42:18.728+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '100', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmp2mhx9h24']
[2024-06-18T16:42:18.741+0000] {standard_task_runner.py:91} INFO - Job 100: Subtask fetch_nba_scores
[2024-06-18T16:42:18.742+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=7793) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T16:42:18.743+0000] {standard_task_runner.py:63} INFO - Started process 7873 to run task
[2024-06-18T16:42:18.932+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T16:42:19.168+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T16:42:19.169+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T16:42:19.221+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T16:42:19.221+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T16:42:19.276+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T164218, end_date=20240618T164219
[2024-06-18T16:42:19.330+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T16:42:19.357+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/models/baseoperator.py:1297 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2024-06-18T16:42:19.377+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T16:42:19.379+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T16:49:03.184+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T16:49:03.267+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:49:03.275+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T16:49:03.275+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T16:49:03.293+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T16:49:03.308+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '114', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmphr10qgkn']
[2024-06-18T16:49:03.319+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=11680) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T16:49:03.319+0000] {standard_task_runner.py:63} INFO - Started process 11759 to run task
[2024-06-18T16:49:03.315+0000] {standard_task_runner.py:91} INFO - Job 114: Subtask fetch_nba_scores
[2024-06-18T16:49:03.462+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T16:49:03.693+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T16:49:03.694+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T16:49:03.754+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T16:49:03.754+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T16:49:03.815+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T164903, end_date=20240618T164903
[2024-06-18T16:49:03.865+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T16:49:03.893+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/models/baseoperator.py:1297 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2024-06-18T16:49:03.912+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T16:49:03.914+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T17:37:18.109+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T17:37:18.188+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T17:37:18.208+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T17:37:18.208+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T17:37:18.227+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T17:37:18.244+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2777) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T17:37:18.245+0000] {standard_task_runner.py:63} INFO - Started process 2870 to run task
[2024-06-18T17:37:18.248+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '139', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpjdwg7l8o']
[2024-06-18T17:37:18.254+0000] {standard_task_runner.py:91} INFO - Job 139: Subtask fetch_nba_scores
[2024-06-18T17:37:18.450+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T17:37:18.681+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T17:37:18.685+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T17:37:18.744+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T17:37:18.744+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T17:37:18.802+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T173718, end_date=20240618T173718
[2024-06-18T17:37:18.831+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T17:37:18.875+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T17:37:18.877+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T18:29:41.014+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T18:29:41.083+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:29:41.094+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:29:41.095+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T18:29:41.119+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T18:29:41.139+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '175', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmph7vps1_2']
[2024-06-18T18:29:41.148+0000] {standard_task_runner.py:91} INFO - Job 175: Subtask fetch_nba_scores
[2024-06-18T18:29:41.151+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=13531) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T18:29:41.152+0000] {standard_task_runner.py:63} INFO - Started process 13675 to run task
[2024-06-18T18:29:41.290+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T18:29:41.490+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T18:29:41.491+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T18:29:41.544+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T18:29:41.544+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T18:29:41.603+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T182941, end_date=20240618T182941
[2024-06-18T18:29:41.657+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T18:29:41.709+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T18:29:41.713+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T18:40:35.116+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T18:40:35.191+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:40:35.200+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:40:35.201+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T18:40:35.219+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T18:40:35.234+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=17697) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T18:40:35.236+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '201', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpbmg_mq__']
[2024-06-18T18:40:35.235+0000] {standard_task_runner.py:63} INFO - Started process 17772 to run task
[2024-06-18T18:40:35.241+0000] {standard_task_runner.py:91} INFO - Job 201: Subtask fetch_nba_scores
[2024-06-18T18:40:35.411+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T18:40:35.625+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T18:40:35.626+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T18:40:35.673+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T18:40:35.673+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T18:40:35.725+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T184035, end_date=20240618T184035
[2024-06-18T18:40:35.744+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T18:40:35.788+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T18:40:35.794+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T18:53:20.570+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T18:53:20.619+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:53:20.626+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T18:53:20.627+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T18:53:20.646+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T18:53:20.666+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=21514) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T18:53:20.670+0000] {standard_task_runner.py:63} INFO - Started process 21590 to run task
[2024-06-18T18:53:20.666+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '220', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmp1xwvyhiw']
[2024-06-18T18:53:20.671+0000] {standard_task_runner.py:91} INFO - Job 220: Subtask fetch_nba_scores
[2024-06-18T18:53:20.808+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T18:53:21.058+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T18:53:21.060+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T18:53:21.112+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T18:53:21.112+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T18:53:21.163+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T185320, end_date=20240618T185321
[2024-06-18T18:53:21.210+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T18:53:21.256+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T18:53:21.260+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T19:08:46.972+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T19:08:47.050+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T19:08:47.066+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T19:08:47.066+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T19:08:47.088+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T19:08:47.109+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '239', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpy5syomtd']
[2024-06-18T19:08:47.121+0000] {standard_task_runner.py:91} INFO - Job 239: Subtask fetch_nba_scores
[2024-06-18T19:08:47.119+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=28017) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T19:08:47.122+0000] {standard_task_runner.py:63} INFO - Started process 28049 to run task
[2024-06-18T19:08:47.241+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T19:08:47.475+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T19:08:47.477+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T19:08:47.626+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T19:08:47.626+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T19:08:47.678+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T190847, end_date=20240618T190847
[2024-06-18T19:08:47.702+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T19:08:47.746+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T19:08:47.751+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T19:18:26.597+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T19:18:26.664+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T19:18:26.672+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T19:18:26.673+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T19:18:26.689+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T19:18:26.713+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=32001) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T19:18:26.716+0000] {standard_task_runner.py:63} INFO - Started process 32110 to run task
[2024-06-18T19:18:26.712+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '260', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpm4ze9mtp']
[2024-06-18T19:18:26.717+0000] {standard_task_runner.py:91} INFO - Job 260: Subtask fetch_nba_scores
[2024-06-18T19:18:26.902+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T19:18:27.092+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T19:18:27.093+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T19:18:27.207+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T19:18:27.207+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T19:18:27.260+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T191826, end_date=20240618T191827
[2024-06-18T19:18:27.296+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T19:18:27.342+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T19:18:27.344+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-18T20:33:09.594+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-18T20:33:09.790+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T20:33:09.832+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [queued]>
[2024-06-18T20:33:09.833+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-18T20:33:09.875+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): fetch_nba_scores> on 2024-06-17 00:00:00+00:00
[2024-06-18T20:33:09.928+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'nba_data_pipeline', 'fetch_nba_scores', 'scheduled__2024-06-17T00:00:00+00:00', '--job-id', '275', '--raw', '--subdir', 'DAGS_FOLDER/nba_news_stats_etl.py', '--cfg-path', '/tmp/tmpsrmzro3g']
[2024-06-18T20:33:09.948+0000] {standard_task_runner.py:91} INFO - Job 275: Subtask fetch_nba_scores
[2024-06-18T20:33:09.947+0000] {logging_mixin.py:188} WARNING - /home/ubuntu/nba_ns_venv/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2132) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-18T20:33:09.950+0000] {standard_task_runner.py:63} INFO - Started process 2271 to run task
[2024-06-18T20:33:10.318+0000] {task_command.py:426} INFO - Running <TaskInstance: nba_data_pipeline.fetch_nba_scores scheduled__2024-06-17T00:00:00+00:00 [running]> on host ip-172-31-45-144.ec2.internal
[2024-06-18T20:33:10.660+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Airflow' AIRFLOW_CTX_DAG_ID='nba_data_pipeline' AIRFLOW_CTX_TASK_ID='fetch_nba_scores' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-17T00:00:00+00:00'
[2024-06-18T20:33:10.662+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-18T20:33:10.727+0000] {python.py:237} INFO - Done. Returned value was: /home/ubuntu/dags/nba_news_stats_data/nba_scores.json
[2024-06-18T20:33:10.727+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-18T20:33:10.793+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=nba_data_pipeline, task_id=fetch_nba_scores, run_id=scheduled__2024-06-17T00:00:00+00:00, execution_date=20240617T000000, start_date=20240618T203309, end_date=20240618T203310
[2024-06-18T20:33:10.871+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-18T20:33:10.961+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-06-18T20:33:10.964+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
